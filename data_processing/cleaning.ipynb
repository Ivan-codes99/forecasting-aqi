{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../filtered_pollution_us_2000_2016.csv')\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display columns\n",
    "print(f\"Features from deafult dataset:\\n {data.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(f\"Missing values in each feature: \\n{data.isnull().sum()}\")\n",
    "\n",
    "# Checking for duplicate rows\n",
    "print(f\"\\nNumber of duplicate rows in dataset: \\n{data.duplicated().sum()}\")\n",
    "\n",
    "# Dropping any duplicate rows\n",
    "data.drop_duplicates(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before checking threshold for features\n",
    "number_rows, number_columns = data.shape\n",
    "print(f\"Raw Data: {number_rows} samples and {number_columns} features\")\n",
    "\n",
    "\n",
    "# Removing Any Feature with >= 80% Missing Values\n",
    "threshold = 0.8\n",
    "retain_columns = [col for col in data.columns if data[col].isnull().mean() < threshold]\n",
    "data = data[retain_columns]\n",
    "\n",
    "print(f\"Features Retained After Removing >= 80% Missing Values: {len(retain_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving the NaN values for SO2 AQI\n",
    "\n",
    "# Split Data where there are NaN and Non-NaN values\n",
    "features = [\"SO2 Mean\", \"SO2 1st Max Value\", \"SO2 1st Max Hour\"]\n",
    "so2_known = data.dropna(subset=[\"SO2 AQI\"])\n",
    "so2_unknown = data[data[\"SO2 AQI\"].isna()]\n",
    "\n",
    "# Using Linear Regression to fill in where NaN exists\n",
    "so2_model = LinearRegression().fit(so2_known[features], so2_known[\"SO2 AQI\"])\n",
    "data.loc[data[\"SO2 AQI\"].isna(), \"SO2 AQI\"] = so2_model.predict(so2_unknown[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solving the NaN values for CO AQI\n",
    "\n",
    "# Split Data where there are NaN and Non-NaN values\n",
    "features = [\"CO Mean\", \"CO 1st Max Value\", \"CO 1st Max Hour\"]\n",
    "co_known = data.dropna(subset=[\"CO AQI\"])\n",
    "co_unknown = data[data[\"CO AQI\"].isna()]\n",
    "\n",
    "# Using Linear Regression to fill in where NaN exists\n",
    "co_model = LinearRegression().fit(co_known[features], co_known[\"CO AQI\"])\n",
    "data.loc[data[\"CO AQI\"].isna(), \"CO AQI\"] = co_model.predict(co_unknown[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how many zeros before cleaning\n",
    "before_cleaning_data = (data == 0).sum()\n",
    "print(f\"Number of zeros in each feature before cleaning: \\n{before_cleaning_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimiinating any negative or zero values from the data set\n",
    "data_cleaned = data[(data > 0).all(axis=1)].copy()\n",
    "\n",
    "#Checking to see hoa many zeros after cleaning\n",
    "after_cleaning_data = (data_cleaned == 0).sum()\n",
    "print(f\"\\nNumber of zeros in each feature after cleaning: \\n{after_cleaning_data}\")\n",
    "\n",
    "# Checking length of data\n",
    "print(f\"\\nTotal length of Data after cleaning: \\n{len(data_cleaned)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the Overall AQI by taking the max across the specified columns\n",
    "data_cleaned.loc[:, \"Overall AQI\"] = data_cleaned[['NO2 AQI', 'O3 AQI', 'SO2 AQI', 'CO AQI']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats\n",
    "data_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_check = ['NO2 AQI', 'O3 AQI', 'CO AQI', 'SO2 AQI', 'Overall AQI']\n",
    "\n",
    "upper_limit = 200\n",
    "\n",
    "for column in data_cleaned.columns:\n",
    "    \n",
    "    Q1 = data_cleaned[column].quantile(0.25)\n",
    "    Q3 = data_cleaned[column].quantile(0.75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "\n",
    "    data_cleaned = data_cleaned[(data_cleaned[column] >= lower_bound) & (data_cleaned[column] <= upper_limit)]\n",
    "\n",
    "data_cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making new csv with only these columns\n",
    "file_path = os.path.join(os.getcwd(), '../../cleaned_dataset.csv')\n",
    "data_cleaned.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
